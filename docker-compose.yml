###
### BEFORE RUNNING

# DEV SETTINGS:
### nuxt.config.js
#       baseURL: 'http://127.0.0.1:5000',
#       https: false,


# PROD SETTINGS:
### nuxt.config.js
#       baseURL: #'http://api.tax-automation.com' # at the moment false, later --> #'https://api.tax-automation.com',
#       https: false # at the moment false, later --> #true,



version: '3'

services:

    front:
        container_name: front
        build:
            context: ./front
            dockerfile: Dockerfile
            args:
                - NODE_VERSION=${NODE_VERSION}
        image: ${OWNER_NAME}/front:${VERSION_NUMBER}
        restart: always
        expose: # EXPOSE only opens up a port within a docker network, while PORTS allows access from the outside world (the internet)
            - "3000"
        depends_on:
            - api
        networks:
            - web
        command: "npm run start"




    # ## new
    rabbitmq:
        container_name: rabbitmq
        image: rabbitmq:management #3-alpine
        ports:
            - "15672:15672"
            - "5672:5672"
        healthcheck:
            test: ['CMD', 'rabbitmqctl', 'status']
            interval: 30s
            timeout: 15s
            retries: 3
        networks:
            - internal
            - web

    redis:
        container_name: redis
        image: redis:5-alpine
        ports:
            - "6379:6379"
        healthcheck:
            test: ['CMD', 'redis-cli', 'ping']
            interval: 30s
            timeout: 15s
            retries: 3
        networks:
            - internal


    celery-worker:
        container_name: celery-worker
        build:
            context: ./api
            dockerfile: Dockerfile
            args:
                - PYTHON_VERSION=${PYTHON_VERSION}
        image: celery:latest
        ports:
            - "5555:5555"
        depends_on:
            - rabbitmq
            - redis
        networks:
            - internal
                                    #The -A option gives Celery the application module and the Celery instance
        command: bash -c "celery worker -A wsgi:celery -P gevent --concurrency=1000 --loglevel=info"


    flower:
        # https://www.distributedpython.com/2018/10/13/flower-docker/
        container_name: flower
        image: mher/flower
        expose:
            - "8888"
        # ports:
        #     - 8888:8888
        depends_on:
            - celery-worker
        networks:
            - internal


    # ##^#new


    api:
        container_name: api
        build:
            context: ./api
            dockerfile: Dockerfile
            args:
                - PYTHON_VERSION=${PYTHON_VERSION}
        image: ${OWNER_NAME}/api:${VERSION_NUMBER}
        restart: always
        expose:
            - "5000"
        depends_on: # depends_on defines the order in which the services are started
            - postgres
            - rabbitmq #new
            - redis #new
            - celery-worker #new
        volumes:
            - logs:/logs
            - seeds:/seeds
            - templates:/templates
            - seller_firm_data:/seller_firm_data
        networks:
            - internal
            - web
        command: bash -c "./wait-for-it.sh postgres:5432 --timeout=2 && gunicorn wsgi:app --bind 0.0.0.0:5000 --timeout 180 --worker-class geventwebsocket.gunicorn.workers.GeventWebSocketWorker --worker-connections 1000 --log-level=info" #gunicorn --bind 0.0.0.0:5000 wsgi:app"


    postgres:
        container_name: postgres
        build:
            context: ./db
            dockerfile: Dockerfile
            args:
                - POSTGRES_VERSION=${POSTGRES_VERSION}
        image: ${OWNER_NAME}/postgres:${VERSION_NUMBER}
        restart: always
        environment:
            - DATABASE=postgres
        expose:
            - "5432"
        volumes:
            - pgdata:/pgdata
        networks:
            - internal

networks:
    internal:
    web:


volumes:
    pgdata:
    logs:
    seeds:
    templates:
    seller_firm_data:
